{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "annot_file = 'Data/slots_data/rhet_data_slots_cleaned_test.json'\n",
    "with open(annot_file, 'r', encoding='utf-8') as f:\n",
    "    lines = json.load(f)\n",
    "    task_input, task_output = [], []\n",
    "    for file in lines:\n",
    "        line = lines[file]\n",
    "        for rhet_tag in line:\n",
    "            # Try training on only 1 task\n",
    "            # if rhet_tag == 'identification':\n",
    "            text = line[rhet_tag]['text']\n",
    "            slots = line[rhet_tag]['slots']\n",
    "            formatted_slot = ''\n",
    "            for slot_key, slot_value in slots.items():\n",
    "                formatted_slot+= '<'+slot_key+':'+slot_value+'>'\n",
    "            task_output.append(text)\n",
    "            task_input.append(formatted_slot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# compile all json outputs \n",
    "\n",
    "# 'gpt_neo',\n",
    "\n",
    "models = ['transformers_bert_base',\n",
    "          't5_base',\n",
    "          'gpt_neo',\n",
    "          'flan_t5_base']\n",
    "\n",
    "suffixes = [f'{i}' for i in range(1,7)]\n",
    "prefix = 'results_greedy_'\n",
    "\n",
    "root_path = 'checkpoints'\n",
    "\n",
    "columns = ['Model','M1','M2', 'M3', 'M4', 'M5', 'M6']\n",
    "data_dict = {k:[] for k in columns}\n",
    "for model in models:\n",
    "    data_dict['Model'].append(model)\n",
    "\n",
    "    for suffix in suffixes:\n",
    "        full_path = os.path.join(root_path, model, prefix+suffix+\".json\")\n",
    "        with open(full_path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            avg_score = (results['rougeL']*100+results['rouge1']*100+results['rouge2']*100+results['bleu']*100+results['bert_score(f1)']*100+results['meteor']*100)/6.0\n",
    "            data_dict[f'M{suffix}'].append(round(avg_score,2))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=data_dict, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformers_bert_base</td>\n",
       "      <td>35.29</td>\n",
       "      <td>38.62</td>\n",
       "      <td>35.03</td>\n",
       "      <td>37.22</td>\n",
       "      <td>51.76</td>\n",
       "      <td>39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5_base</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.99</td>\n",
       "      <td>44.31</td>\n",
       "      <td>49.75</td>\n",
       "      <td>60.98</td>\n",
       "      <td>45.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>41.82</td>\n",
       "      <td>43.79</td>\n",
       "      <td>37.35</td>\n",
       "      <td>40.60</td>\n",
       "      <td>47.75</td>\n",
       "      <td>37.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan_t5_base</td>\n",
       "      <td>50.04</td>\n",
       "      <td>51.23</td>\n",
       "      <td>43.41</td>\n",
       "      <td>48.20</td>\n",
       "      <td>59.46</td>\n",
       "      <td>42.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model     M1     M2     M3     M4     M5     M6\n",
       "0  transformers_bert_base  35.29  38.62  35.03  37.22  51.76  39.54\n",
       "1                 t5_base  52.10  52.99  44.31  49.75  60.98  45.57\n",
       "2                 gpt_neo  41.82  43.79  37.35  40.60  47.75  37.54\n",
       "3            flan_t5_base  50.04  51.23  43.41  48.20  59.46  42.47"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('task_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model:  transformers_bert_base\n",
      "path:  checkpoints/transformers_bert_base/results_sampling_topk_topp.json\n",
      " & 39.88 & 14.24 & 27.8 & 13.1 & 32.95 & 88.44 & 87.96 & 88.19 & 36.03\n",
      "\n",
      " model:  t5_base\n",
      "path:  checkpoints/t5_base/results_sampling_topk_topp.json\n",
      " & 52.16 & 27.03 & 37.33 & 22.07 & 45.05 & 91.4 & 90.96 & 91.17 & 45.8\n",
      "\n",
      " model:  gpt_neo\n",
      "path:  checkpoints/gpt_neo/results_sampling_topk_topp.json\n",
      " & 39.36 & 18.94 & 26.6 & 10.0 & 42.0 & 87.15 & 90.83 & 88.94 & 37.64\n",
      "\n",
      " model:  flan_t5_base\n",
      "path:  checkpoints/flan_t5_base/results_sampling_topk_topp.json\n",
      " & 53.65 & 29.35 & 39.21 & 25.19 & 47.41 & 91.48 & 91.28 & 91.37 & 47.7\n"
     ]
    }
   ],
   "source": [
    "# code for decoding results\n",
    "models = ['transformers_bert_base',\n",
    "          't5_base',\n",
    "          'gpt_neo',\n",
    "          'flan_t5_base']\n",
    "\n",
    "\n",
    "decoding = 'sampling_topk_topp'\n",
    "scores = ['rouge1','rouge2', 'rougeL','bleu','meteor','bert_score(p)','bert_score(r)','bert_score(f1)']\n",
    "\n",
    "\n",
    "root_path = 'checkpoints'\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    print('\\n model: ', model)\n",
    "    \n",
    "    full_path = os.path.join(root_path, model, f'results_{decoding}.json')\n",
    "    print('path: ', full_path)\n",
    "    with open(full_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    display_str = ' & '\n",
    "    total = 0\n",
    "    for score in scores:\n",
    "        if score not in ['bert_score(p)','bert_score(r)']:\n",
    "            total+=round(results[score]*100,2)\n",
    "\n",
    "        display_str+=str(round(results[score]*100,2))+' & '\n",
    "    display_str+= str(round((total/6),2))\n",
    "    print(display_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error file: ../data/rhet_data\\\\205ChD_180926FoodEN.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
